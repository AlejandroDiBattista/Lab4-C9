{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuente de datos\n",
    "\n",
    "La base MNIST (\"Modified National Institute of Standards and Technology\") es un conjunto de datos de imágenes de dígitos escritos a mano. Contiene 60,000 imágenes de entrenamiento y 10,000 imágenes de prueba. Las imágenes están en escala de grises y tienen un tamaño de 28x28 píxeles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torchvision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mMNIST(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(images[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      4\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torchvision' is not defined"
     ]
    }
   ],
   "source": [
    "images = torchvision.datasets.MNIST('data', train=True, download=True)\n",
    "print(images[0][1])\n",
    "\n",
    "fig, ax = plt.subplots(4, 4)\n",
    "for (imagen, etiqueta), ax in zip(images, ax.flatten()):\n",
    "    ax.imshow(imagen, cmap='Greys')\n",
    "    ax.set_title('Label: %i' % etiqueta)\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos de entrenamiento y prueba\n",
    "\n",
    "Cargamos las imagenes en tensores de PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datasets de entrenamiento y prueba\n",
    "\n",
    "imagenes = torchvision.datasets.MNIST('data', train=True,  download=True, transform=torchvision.transforms.ToTensor())\n",
    "probar   = torchvision.datasets.MNIST('data', train=False, download=True, transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición del dispositivo \n",
    "\n",
    "Se elige el dsipositivo de entrenamiento\n",
    "* cpu : Corre un una pc normal\n",
    "* cuda : Corre un una placa de video Nvidia \n",
    "* mps : Corre en nueral engine de Apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las redes funcionaran en mps\n"
     ]
    }
   ],
   "source": [
    "# Definir el dispositivo\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# device = \"cpu\"  # Descomentar para forzar el uso de la CPU\n",
    "print(f\"Las redes funcionaran en {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Neuronal Simple \n",
    "\n",
    "Esta implementación es una red neuronal simple. \n",
    "Consiste en un perceptrón para cada dígito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clasificador(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Linear(28*28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(start_dim=1)   # Aplanar la imagen\n",
    "        x = self.c1(x)\n",
    "        return x\n",
    "\n",
    "    def fit(self, dataset, lr=0.1, epochs=10):\n",
    "        cargador  = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=lr)\n",
    "\n",
    "        # Mover el modelo al dispositivo\n",
    "        self.to(device)\n",
    "        \n",
    "        # Entrenamiento de la red\n",
    "        start = time.time()\n",
    "\n",
    "        self.train()\n",
    "        for epoch in range(epochs):\n",
    "            start_time = time.time()\n",
    "            for images, labels in cargador:\n",
    "                # Mover imágenes y etiquetas al dispositivo\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                # Adelante + retropropagación + optimización\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            duration = time.time() - start_time  # Calcular la duración de la época\n",
    "            print(f'- Epoch {epoch+1}, Loss: {loss.item():.4f}, Duration: {duration:3.1f}s')\n",
    "        print(f'  Training time: {time.time() - start:3.1f}s')\n",
    "\n",
    "    def score(self, dataset):\n",
    "        cargador = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=False)\n",
    "        # Mover el modelo al dispositivo\n",
    "        self.to(device)\n",
    "        \n",
    "        # Evaluación del modelo\n",
    "        self.eval()\n",
    "        correctos = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():  # No necesitamos calcular gradientes para la evaluación\n",
    "            for images, labels in cargador:\n",
    "                # Mover imágenes y etiquetas al dispositivo\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = self(images)\n",
    "                _, predicciones = torch.max(outputs, 1)\n",
    "                correctos += (predicciones == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        return correctos / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶︎ Red Simple (mps)\n",
      "- Epoch 1, Loss: 0.3507, Duration: 1.9s\n",
      "- Epoch 2, Loss: 0.2431, Duration: 1.7s\n",
      "- Epoch 3, Loss: 0.2689, Duration: 1.8s\n",
      "- Epoch 4, Loss: 0.3012, Duration: 2.1s\n",
      "- Epoch 5, Loss: 0.1836, Duration: 2.1s\n",
      "  Training time: 9.7s\n",
      "▪︎ Precisión: 92.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"▶︎ Red Simple ({device})\")\n",
    "\n",
    "red = Clasificador()\n",
    "red.fit(imagenes, lr=0.1, epochs=5)\n",
    "\n",
    "# Evaluar el modelo con el conjunto de prueba\n",
    "print(f\"▪︎ Precisión: {red.score(probar):3.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Neuronal Multicapa\n",
    "\n",
    "Esta implementación es una red neuronal multicapa.\n",
    "Consiste en una capa de entrada de 784 neuronas, dos capas ocultas de 128 y 64 neuronas y una capa de salida de 10 neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClasificadorProfundo(Clasificador):\n",
    "    def __init__(self):\n",
    "        super(ClasificadorProfundo, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)   # Primera capa oculta\n",
    "        self.fc2 = nn.Linear(128, 64)        # Segunda capa oculta\n",
    "        self.fc3 = nn.Linear(64, 10)         # Capa de salida\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(start_dim=1)   # Aplanar la imagen\n",
    "        x = torch.relu(self.fc1(x))  # Activación ReLU en la primera capa\n",
    "        x = torch.relu(self.fc2(x))  # Activación ReLU en la segunda capa\n",
    "        return self.fc3(x)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶︎ Red Profunda (mps)\n",
      "- Epoch 1, Loss: 0.4320, Duration: 2.2s\n",
      "- Epoch 2, Loss: 0.2456, Duration: 2.0s\n",
      "- Epoch 3, Loss: 0.1206, Duration: 2.1s\n",
      "- Epoch 4, Loss: 0.0948, Duration: 2.2s\n",
      "- Epoch 5, Loss: 0.1313, Duration: 1.9s\n",
      "  Training time: 10.4s\n",
      "▪︎ Precisión: 96.8%\n"
     ]
    }
   ],
   "source": [
    "print(f\"▶︎ Red Profunda ({device})\")\n",
    "red = ClasificadorProfundo()\n",
    "red.fit(imagenes, lr=0.1, epochs=5)\n",
    "\n",
    "# Evaluar el modelo con el conjunto de prueba\n",
    "print(f\"▪︎ Precisión: {red.score(probar):3.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Neuronal Convolucional\n",
    "\n",
    "Esta implementacion es una red neuronal convolucional.\n",
    "Consiste en una capa de entrada de 1 canal, una capa convolucional de 32 filtros de 3x3, una capa de pooling de 2x2, una capa convolucional de 64 filtros de 3x3, una capa de pooling de 2x2, una capa densa de 128 neuronas y una capa de salida de 10 neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RedConvolucional(Clasificador):\n",
    "    def __init__(self):\n",
    "        super(RedConvolucional, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)  # Asumiendo 10 clases para clasificación\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # Aplanar\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶︎ Red Convolucional (mps)\n",
      "- Epoch 1, Loss: 0.4717, Duration: 3.7s\n",
      "- Epoch 2, Loss: 0.3657, Duration: 3.5s\n",
      "- Epoch 3, Loss: 0.1754, Duration: 3.7s\n",
      "- Epoch 4, Loss: 0.1962, Duration: 3.5s\n",
      "- Epoch 5, Loss: 0.1912, Duration: 3.5s\n",
      "  Training time: 17.9s\n",
      "▪︎ Precisión: 95.9%\n"
     ]
    }
   ],
   "source": [
    "print(f\"▶︎ Red Convolucional ({device})\")\n",
    "red = RedConvolucional()\n",
    "red.fit(imagenes, lr=0.01, epochs=5)\n",
    "\n",
    "# Evaluar el modelo con el conjunto de prueba\n",
    "print(f\"▪︎ Precisión: {red.score(probar):3.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
